{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Preparing data files\n",
    "\n",
    "Preparing data files according to the [data flowchart](../../datalake.md#data-flowchart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onehealth_data_backend import inout\n",
    "from onehealth_data_backend import preprocess\n",
    "from pathlib import Path\n",
    "import time\n",
    "import xarray as xr\n",
    "from isimip_client.client import ISIMIPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to your own data folder, if needed\n",
    "data_root = Path(\"../../../data/\")\n",
    "data_folder = data_root / \"in/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Download ERA5-Land data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "To download ERA5-Land data using CDS's API:\n",
    "* Select the target dataset, e.g. ERA5-Land monthly averaged data from 1950 to present\n",
    "* Go to tab `Download` of the dataset and select the data variables, time range, geographical area, etc. that you want to download\n",
    "* At the end of the page, click on `Show API request code` and take notes of the following information\n",
    "    * `dataset`: name of the dataset\n",
    "    * `request`: a dictionary summarizes your download request\n",
    "* Replace the values of `dataset` and `request` in the below cell correspondingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace dataset and request with your own values\n",
    "dataset = \"reanalysis-era5-land-monthly-means\"\n",
    "request = {\n",
    "    \"product_type\": [\"monthly_averaged_reanalysis\"],\n",
    "    \"variable\": [\"2m_temperature\", \"total_precipitation\"],\n",
    "    \"year\": [\"2016\", \"2017\"],\n",
    "    \"month\": [\n",
    "        \"01\",\n",
    "        \"02\",\n",
    "        \"03\",\n",
    "        \"04\",\n",
    "        \"05\",\n",
    "        \"06\",\n",
    "        \"07\",\n",
    "        \"08\",\n",
    "        \"09\",\n",
    "        \"10\",\n",
    "        \"11\",\n",
    "        \"12\",\n",
    "    ],\n",
    "    \"time\": [\"00:00\"],\n",
    "    \"data_format\": \"netcdf\",\n",
    "    \"download_format\": \"unarchived\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format = request.get(\"data_format\")\n",
    "\n",
    "# file name of downladed data\n",
    "era5_fname = inout.get_filename(\n",
    "    ds_name=dataset,\n",
    "    data_format=data_format,\n",
    "    years=request[\"year\"],\n",
    "    months=request[\"month\"],\n",
    "    has_area=bool(\"area\" in request),\n",
    "    base_name=\"era5_data\",\n",
    "    variable=request[\"variable\"],\n",
    ")\n",
    "era5_fpath = data_folder / era5_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "if not era5_fpath.exists():\n",
    "    print(\"Downloading data...\")\n",
    "    inout.download_data(era5_fpath, dataset, request)\n",
    "else:\n",
    "    print(\"Data already exists at {}\".format(era5_fpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Special download for total precipitation data from ERA5-Land Hourly dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "`P-model` requires total precipitation data downloaded from dataset `ERA5-Land hourly data from 1950 to present`.\n",
    "\n",
    "Due to the nature of this dataset, value at `00:00` is total precipitation of the previous day (see [here](https://confluence.ecmwf.int/pages/viewpage.action?pageId=197702790))\n",
    "\n",
    "To get correct precipitation values from `01.01.2016` to `31.12.2017`, we need to download data from `02.01.2016` to `01.01.2018`. The current CDS request API does not allow downloading data in a single request for ranges that are not full calendar years.\n",
    "\n",
    "We implemented a special function for this case.\n",
    "\n",
    "```python\n",
    "def download_total_precipitation_from_hourly_era5_land(\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    area: List[float] | None = None,\n",
    "    out_dir: Path = Path(\".\"),\n",
    "    base_name: str = \"era5_data\",\n",
    "    data_format: str = \"netcdf\",\n",
    "    ds_name: str = \"reanalysis-era5-land\",\n",
    "    coord_name: str = \"valid_time\",\n",
    "    var_name: str = \"total_precipitation\",\n",
    "    clean_tmp_files: bool = False,\n",
    ") -> str:\n",
    "```\n",
    "\n",
    "Input for this function includes:\n",
    "\n",
    "* `start_date` and `end_date` in the format of \"YYYY-MM-DD\"\n",
    "* `area` indicates the area to download; `None` means the entire globe.\n",
    "* `out_dir`: output directory to store the downloaded file\n",
    "* `base_name`: base string used to name the output file. File name is described in [Naming convention - Special case](../../data.md#special-case)\n",
    "* `data_format`: can be `netcdf` or `grib`\n",
    "* `ds_name`, `coord_name`, and `var_name` represent the dataset name, coordinate name, and data variable name in the dataset. Please only change these values when CDS changes the corresponding names.\n",
    "* `clean_tmp_files` parameter can be set to `False` to retain the downloaded temporary files, which store data for smaller sub-ranges derived from the overall date range. For example, the range `2016-01-01` to `2017-12-31` would be split into sub-ranges `2016-01-02` to `2016-12-31`, `2017-01-01` to `2017-12-31`, and `2018-01-01` to `2018-01-01`, because the timestamps are shifted one day forward.\n",
    "\n",
    "The function handles time shifting, downloads the data, adjusts the time coordinate back to the target range, and returns the output file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download total precipitation data from ERA5-Land Hourly dataset\n",
    "# from 2016-01-01 to 2017-12-31\n",
    "start_time = \"2016-01-01\"\n",
    "end_time = \"2017-12-31\"\n",
    "tp_era5_hourly_file = inout.download_total_precipitation_from_hourly_era5_land(\n",
    "    start_date=start_time,\n",
    "    end_date=end_time,\n",
    "    area=None,\n",
    "    out_dir=data_folder,\n",
    "    base_name=\"era5_data\",\n",
    "    data_format=\"netcdf\",\n",
    "    ds_name=\"reanalysis-era5-land\",\n",
    "    coord_name=\"valid_time\",\n",
    "    var_name=\"total_precipitation\",\n",
    "    clean_tmp_files=False,  # keep temporary files for checking\n",
    ")\n",
    "tp_era5_hourly_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_era5_hourly_ds = xr.open_dataset(tp_era5_hourly_file)\n",
    "tp_era5_hourly_ds[\"valid_time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Download ISIMIP data (population data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "To download ISIMIP data manually, please follow the instruction in [Data](../../data.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "To download the data using ISIMIP's APIs, please perform these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize ISIMIP client\n",
    "client = ISIMIPClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for population data\n",
    "response = client.datasets(\n",
    "    path=\"ISIMIP3a/InputData/socioeconomic/pop/histsoc/population\"\n",
    ")  # this path is similar to the one in ISIMIP's website\n",
    "\n",
    "for dataset in response[\"results\"]:\n",
    "    print(\"Dataset found: {}\".format(dataset[\"path\"]))\n",
    "\n",
    "# download population data file, 1901_2021\n",
    "for dataset in response[\"results\"]:\n",
    "    for file in dataset[\"files\"]:\n",
    "        if \"1901_2021\" in file[\"name\"]:\n",
    "            isimip_fpath = data_folder / file[\"name\"]\n",
    "            if isimip_fpath.exists():\n",
    "                print(f\"Population data file already exists: {file['name']}\")\n",
    "            else:\n",
    "                print(f\"Downloading population data file: {file['name']}\")\n",
    "                client.download(file[\"file_url\"], path=data_folder)\n",
    "            break  # exit after first match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "We use `preprocess` module to perform preprocessing steps, using function named `preprocess_data_file()`\n",
    "\n",
    "```python\n",
    "def preprocess_data_file(\n",
    "    netcdf_file: Path,\n",
    "    source: Literal[\"era5\", \"isimip\"] = \"era5\",\n",
    "    settings: Path | str = \"default\",\n",
    "    new_settings: Dict[str, Any] | None = None,\n",
    "    unique_tag: str | None = None,\n",
    ") -> Tuple[xr.Dataset, str]:\n",
    "```\n",
    "\n",
    "Here, `netcdf_file` holds the path file, while `source` indicates whether the `.nc` file is downloaded from ERA5-Land or ISIMIP as these two sources have different preprocessing steps.\n",
    "\n",
    "We determine preprocessing steps using a JSON settings file, providied through the `settings` parameter. This parameter can either be set to a file path or to the string `\"default\"`. If a file path is given, the settings will be loaded from that file; if loading fails, the default settings for the corresponding source will be used instead. If `\"default\"` is specified, the default settings of the relevant source are loaded directly.\n",
    "\n",
    "If only certain fields of the default settings need to be updated, these fields and their values can be supplied as a dictionary via the `new_settings` parameter.\n",
    "\n",
    "The final settings used for preprocessing are saved to a file in the same directory as the preprocessed `.nc` file. This output directory is defined in the provided settings file. The `unique_tag` is appended to both the settings file and the resulting `.nc` file to link them together.\n",
    "\n",
    "The following subsections illustrate how preprocessing is applied to ERA5-Land data and ISIMIP data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Preprocess ERA5-Land data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Default settings for `.nc` files from ERA5-Land are:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"output_dir\": \"../../../data/processed\",\n",
    "    \"adjust_longitude\": true,\n",
    "    \"adjust_longitude_vname\": \"longitude\",\n",
    "    \"adjust_longitude_fname\": \"adjlon\",\n",
    "    \"convert_kelvin_to_celsius\": true,\n",
    "    \"convert_kelvin_to_celsius_vname\": \"t2m\",\n",
    "    \"convert_kelvin_to_celsius_fname\": \"celsius\",\n",
    "    \"convert_m_to_mm_precipitation\": true,\n",
    "    \"convert_m_to_mm_precipitation_vname\": \"tp\",\n",
    "    \"convert_m_to_mm_precipitation_fname\": \"mm\",\n",
    "    \"resample_grid\": true,\n",
    "    \"resample_grid_vname\": [\"latitude\", \"longitude\"],\n",
    "    \"resample_degree\": 0.5,\n",
    "    \"resample_grid_fname\": \"deg_trim\",\n",
    "    \"unify_coords\": true,\n",
    "    \"unify_coords_fname\": \"unicoords\",\n",
    "    \"uni_coords\": {\n",
    "        \"valid_time\": \"time\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "The output directory for all preprocessed files and utilized settings files is set to path `\"data/processed\"`. This path is ***relative*** to the current file. For `.nc` files downloaded from ERA5-Land, we need to perform the following preprocessing steps:\n",
    "\n",
    "* adjust longitude from range $[0..360]$ to $[-180..180]$\n",
    "* convert temperature values from Kelvin to Celsius\n",
    "* convert precipitation values from meter to millimeter\n",
    "* resample the grid from $0.1°$ to $0.5°$\n",
    "* rename coordinates to a unified name set, i.e. `latitude`, `longitude`, and `time`\n",
    "\n",
    "We toggle these steps by setting the corresponding field to `true` or `false`, e.g. `\"unify_coords\": false` disables coordinate renaming\n",
    "\n",
    "Fields end with `_vname` specify which data variables in a `.nc` file will be used for the corresponding preprocessing step. While fields with `_fname` define the suffix to add into the file name after the preprocessing step run successfully. For an overview of file name transformation, see [Data](../../data.md).\n",
    "\n",
    "Ultimately, the `uni_coords` dictionary defines the mapping between old and new coordinate names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Preprocessing ERA5-Land data: {era5_fpath}\")\n",
    "t0 = time.time()\n",
    "preprocessed_dataset, era5_pfname = preprocess.preprocess_data_file(\n",
    "    netcdf_file=era5_fpath,\n",
    "    source=\"era5\",\n",
    "    settings=\"default\",\n",
    "    new_settings=None,\n",
    "    unique_tag=None,\n",
    ")\n",
    "t_preprocess = time.time()\n",
    "print(f\"Preprocessing completed in {t_preprocess - t0:.2f} seconds.\")\n",
    "print(f\"Name of preprocessed file: {era5_pfname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Preprocess population data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Default settings for `.nc` files from ISIMIP are:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"output_dir\": \"../../../data/processed\",\n",
    "    \"truncate_date\": true,\n",
    "    \"truncate_date_from\": \"2016-01-01\",\n",
    "    \"truncate_date_to\": \"2017-12-31\",\n",
    "    \"truncate_date_vname\": \"time\",\n",
    "    \"unify_coords\": true,\n",
    "    \"unify_coords_fname\": \"unicoords\",\n",
    "    \"uni_coords\": {\n",
    "        \"lat\": \"latitude\",\n",
    "        \"lon\": \"longitude\"\n",
    "    }\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "The resulting files (data and settings) will be saved into `output_dir` (***relative*** path to the current file). To preprocess `.nc` files from ISIMIP, we consider these steps:\n",
    "\n",
    "* truncate data in a specific range, with start and end timepoints included\n",
    "* unify coordinate names\n",
    "\n",
    "The naming convention for fields in these settings follows the same pattern described above for ERA5-Land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Preprocessing ISIMIP data: {isimip_fpath}\")\n",
    "t0 = time.time()\n",
    "preprocessed_popu, isimip_pfname = preprocess.preprocess_data_file(\n",
    "    netcdf_file=isimip_fpath,\n",
    "    source=\"isimip\",\n",
    "    settings=\"default\",\n",
    "    new_settings=None,\n",
    "    unique_tag=None,\n",
    ")\n",
    "t_popu = time.time()\n",
    "print(f\"Preprocessing ISIMIP data completed in {t_popu - t0:.2f} seconds.\")\n",
    "print(f\"Name of preprocessed file: {isimip_pfname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Aggregate data by NUTS regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "For analyzing data across European regions, it is more convenient to work with data aggregated by NUTS regions rather than by grid points (latitude and longitude). In this section, we demonstrate how ERA5‑Land and ISIMIP population data can be aggregated into NUTS regions.\n",
    "\n",
    "This feature can also be applied to other datasets in NetCDF format that include the coordinates `latitude`, `longitude`, and `time` (e.g. prediction model outputs).\n",
    "\n",
    "To download NUTS data from Eurostat, see [Data](../../data.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUTS shapefile\n",
    "nuts_file = data_folder / \"NUTS_RG_20M_2024_4326.shp.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "We can aggregate single or multiple `.nc` files with one NUTS shape file. These `.nc` files should be structured into a dictionary, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_folder = data_root / \"processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forming a dictionary for non-NUTS data\n",
    "# key is name of the dataset, value is a tuple of (file path, aggregation mapping dict.)\n",
    "non_nuts_data = {\n",
    "    \"era5\": (processed_folder / era5_pfname, None),\n",
    "    \"popu\": (processed_folder / isimip_pfname, None),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Here, the keys represent dataset names (used to form the resulting file name), and the values are tuples containing the file path and the aggregation mapping.\n",
    "\n",
    "By default, the aggregation mapping is set to `None`, which means the `mean` function will be applied to all data variables during aggregation.\n",
    "\n",
    "An example of aggregation mapping dictionary is:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"t2m\": \"mean\", \n",
    "    \"tp\": \"sum\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "The resulting file name would be:\n",
    "\n",
    "`<NUTS_shapefile_name>_agg_<nc_dataset_names>_<min_yyyy-mm>-<max_yyyy-mm>.nc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate data by NUTS regions\n",
    "t0 = time.time()\n",
    "aggregated_file = preprocess.aggregate_data_by_nuts(\n",
    "    non_nuts_data, nuts_file, normalize_time=True, output_dir=processed_folder\n",
    ")\n",
    "t1 = time.time()\n",
    "print(f\"Aggregation completed in {t1 - t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "In this example, the `normalize_time` option ensures that time values in the `.nc` file are reset to the start of the day. For example, `2025-10-01T12:00:00` becomes `2025-10-01T00:00:00`. This is particularly useful for population data, where time values are recorded at midday.\n",
    "\n",
    "When `output_dir` is set to `None`, the aggregated file is saved in the same directory as the NUTS shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the aggregated data\n",
    "agg_ds = xr.open_dataset(aggregated_file)\n",
    "agg_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ds[[\"t2m\", \"total-population\"]].sel(NUTS_ID=\"DE\").to_dataframe().tail(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onehealthdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
