{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Preparing data files\n",
    "\n",
    "Preparing data files according to the [data flowchart](../../../datalake_database/#data-flowchart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onehealth_data_backend import inout\n",
    "from onehealth_data_backend import preprocess\n",
    "from pathlib import Path\n",
    "import time\n",
    "import xarray as xr\n",
    "from isimip_client.client import ISIMIPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to your own data folder, if needed\n",
    "data_folder = Path(\"../../../data/in/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Download ERA5-Land data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "To download ERA5-Land data using CDS's API:\n",
    "* Select the target dataset, e.g. ERA5-Land monthly averaged data from 1950 to present\n",
    "* Go to tab `Download` of the dataset and select the data variables, time range, geographical area, etc. that you want to download\n",
    "* At the end of the page, click on `Show API request code` and take notes of the following information\n",
    "    * `dataset`: name of the dataset\n",
    "    * `request`: a dictionary summarizes your download request\n",
    "* Replace the values of `dataset` and `request` in the below cell correspondingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace dataset and request with your own values\n",
    "dataset = \"reanalysis-era5-land-monthly-means\"\n",
    "request = {\n",
    "    \"product_type\": [\"monthly_averaged_reanalysis\"],\n",
    "    \"variable\": [\"2m_temperature\", \"total_precipitation\"],\n",
    "    \"year\": [\"2016\", \"2017\"],\n",
    "    \"month\": [\n",
    "        \"01\",\n",
    "        \"02\",\n",
    "        \"03\",\n",
    "        \"04\",\n",
    "        \"05\",\n",
    "        \"06\",\n",
    "        \"07\",\n",
    "        \"08\",\n",
    "        \"09\",\n",
    "        \"10\",\n",
    "        \"11\",\n",
    "        \"12\",\n",
    "    ],\n",
    "    \"time\": [\"00:00\"],\n",
    "    \"data_format\": \"netcdf\",\n",
    "    \"download_format\": \"unarchived\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format = request.get(\"data_format\")\n",
    "\n",
    "# file name of downladed data\n",
    "era5_fname = inout.get_filename(\n",
    "    ds_name=dataset,\n",
    "    data_format=data_format,\n",
    "    years=request[\"year\"],\n",
    "    months=request[\"month\"],\n",
    "    has_area=bool(\"area\" in request),\n",
    "    base_name=\"era5_data\",\n",
    "    variable=request[\"variable\"],\n",
    ")\n",
    "era5_fpath = data_folder / era5_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "if not era5_fpath.exists():\n",
    "    print(\"Downloading data...\")\n",
    "    inout.download_data(era5_fpath, dataset, request)\n",
    "else:\n",
    "    print(\"Data already exists at {}\".format(era5_fpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Download ISIMIP data (population data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "To download ISIMIP data manually, please follow the instruction in [Data](../../data.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "To download the data using ISIMIP's APIs, please perform these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize ISIMIP client\n",
    "client = ISIMIPClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for population data\n",
    "response = client.datasets(\n",
    "    path=\"ISIMIP3a/InputData/socioeconomic/pop/histsoc/population\"\n",
    ")  # this path is similar to the one in ISIMIP's website\n",
    "\n",
    "for dataset in response[\"results\"]:\n",
    "    print(\"Dataset found: {}\".format(dataset[\"path\"]))\n",
    "\n",
    "# download population data file, 1901_2021\n",
    "for dataset in response[\"results\"]:\n",
    "    for file in dataset[\"files\"]:\n",
    "        if \"1901_2021\" in file[\"name\"]:\n",
    "            isimip_fpath = data_folder / file[\"name\"]\n",
    "            if isimip_fpath.exists():\n",
    "                print(f\"Population data file already exists: {file['name']}\")\n",
    "            else:\n",
    "                print(f\"Downloading population data file: {file['name']}\")\n",
    "                client.download(file[\"file_url\"], path=data_folder)\n",
    "            break  # exit after first match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "We use `preprocess` module to perform preprocessing steps, using function named `preprocess_data_file()`\n",
    "\n",
    "```python\n",
    "def preprocess_data_file(\n",
    "    netcdf_file: Path,\n",
    "    source: Literal[\"era5\", \"isimip\"] = \"era5\",\n",
    "    settings: Path | str = \"default\",\n",
    "    new_settings: Dict[str, Any] | None = None,\n",
    "    unique_tag: str | None = None,\n",
    ") -> Tuple[xr.Dataset, str]:\n",
    "```\n",
    "\n",
    "Here, `netcdf_file` holds the path file, while `source` indicates whether the `.nc` file is downloaded from ERA5-Land or ISIMIP as these two sources have different preprocessing steps.\n",
    "\n",
    "We determine preprocessing steps using a JSON settings file, providied through the `settings` parameter. This parameter can either be set to a file path or to the string `\"default\"`. If a file path is given, the settings will be loaded from that file; if loading fails, the default settings for the corresponding source will be used instead. If `\"default\"` is specified, the default settings of the relevant source are loaded directly.\n",
    "\n",
    "If only certain fields of the default settings need to be updated, these fields and their values can be supplied as a dictionary via the `new_settings` parameter.\n",
    "\n",
    "The final settings used for preprocessing are saved to a file in the same directory as the preprocessed `.nc` file. This output directory is defined in the provided settings file. The `unique_tag` is appended to both the settings file and the resulting `.nc` file to link them together.\n",
    "\n",
    "The following subsections illustrate how preprocessing is applied to ERA5-Land data and ISIMIP data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Preprocess ERA5-Land data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Default settings for ERA5-Land... TBU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing ERA5-Land data...\")\n",
    "t0 = time.time()\n",
    "preprocessed_dataset = preprocess.preprocess_data_file(\n",
    "    netcdf_file=era5_fpath,\n",
    ")\n",
    "t_preprocess = time.time()\n",
    "print(\"Preprocessing completed in {:.2f} seconds.\".format(t_preprocess - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "The preprocessed dataset is also saved in a `.nc` file under the same folder, namely `era5_data_2016_2017_all_2t_tp_monthly_unicoords_adjlon_celsius_mm_05deg_trim`\n",
    "\n",
    "Details on regulation for the file name can be found in [Data](../../data.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Preprocess population data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Instructions for downloading population data (i.e. ISIMIP data) are presented in [Data](../../data.md) and [Data Lake](../../datalake.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "popu_file = data_folder / \"population_histsoc_30arcmin_annual_1901_2021.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing population data...\")\n",
    "t0 = time.time()\n",
    "preprocessed_popu = preprocess.preprocess_data_file(netcdf_file=isimip_fpath)\n",
    "t_popu = time.time()\n",
    "print(\"Preprocessing population data completed in {:.2f} seconds.\".format(t_popu - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "The preprocessed dataset is also saved in a `.nc` file under the same folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Aggregate data by NUTS regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "For analyzing data across European regions, it is more convenient to work with data aggregated by NUTS regions rather than by grid points (latitude and longitude). In this section, we demonstrate how ERA5‑Land and Population data can be aggregated into NUTS regions.\n",
    "\n",
    "This feature can also be applied to other datasets in NetCDF format that include the coordinates `latitude`, `longitude`, and `time` (e.g. prediction model outputs).\n",
    "\n",
    "*Note: file names of preprocessed era5 and population data should be obtained directly after the `preprocess_data_file()` function ([issue #15](https://github.com/ssciwr/onehealth-data-backend/issues/15))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUTS shapefile\n",
    "nuts_file = data_folder / \"NUTS_RG_20M_2024_4326.shp.zip\"\n",
    "\n",
    "# preprocess ERA5-Land file\n",
    "preprocessed_era5_file = (\n",
    "    data_folder\n",
    "    / \"era5_data_2016_2017_all_2t_tp_monthly_unicoords_adjlon_celsius_mm_05deg_trim.nc\"\n",
    ")\n",
    "\n",
    "# preprocess population file\n",
    "preprocessed_popu_file = (\n",
    "    data_folder / \"population_histsoc_30arcmin_annual_1901_2021_unicoords_2020_2021.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "We can aggregate singple or multiple NetCDF files with one NUTS shape file. These NetCDF files should be structured into a dictionary, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forming a dictionary for non-NUTS data\n",
    "non_nuts_data = {\n",
    "    \"era5\": (preprocessed_era5_file, None),\n",
    "    \"popu\": (preprocessed_popu_file, None),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Here, the keys represent dataset names (used to form the resulting file name), and the values are tuples containing the file path and the aggregation mapping.\n",
    "\n",
    "By default, the aggregation mapping is set to `None`, which means the `mean` function will be applied to all data variables during aggregation.\n",
    "\n",
    "An example of aggregation mapping is:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"t2m\": \"mean\", \n",
    "    \"tp\": \"sum\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "The resulting file name would be:\n",
    "\n",
    "`<NUTS_shapefile_name>_agg_<nc_dataset_names>_<min_yyyy-mm>-<max_yyy-mm>.nc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate data by NUTS regions\n",
    "t0 = time.time()\n",
    "aggregated_file = preprocess.aggregate_data_by_nuts(\n",
    "    non_nuts_data, nuts_file, normalize_time=True, output_dir=None\n",
    ")\n",
    "t1 = time.time()\n",
    "print(f\"Aggregation completed in {t1 - t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "In this example, we use the default values for `normalize_time` and `output_dir`, which are `True` and `None`, respectively.\n",
    "\n",
    "The `normalize_time` option ensures that time values in the NetCDF file are reset to the start of the day. For example, `2025-10-01T12:00:00` becomes `2025-10-01T00:00:00`. This is particularly useful for population data, where time values are recorded at midday.\n",
    "\n",
    "When `output_dir` is set to `None`, the aggregated file is saved in the same directory as the NUTS shapefile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "*Note: Since the ERA5-Land data is for 2016-2017, while the popuation data is for 2020-2021, the aggregated data would range from 2016 to 2021.*\n",
    "\n",
    "*We should truncate the population data to the same time frame for demonstration purpose. Update this after addressing [issue #6](https://github.com/ssciwr/onehealth-data-backend/issues/6)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the aggregated data\n",
    "agg_ds = xr.open_dataset(aggregated_file)\n",
    "agg_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ds[[\"t2m\", \"total-population\"]].sel(NUTS_ID=\"DE\").to_dataframe().tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onehealthdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
