{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Preparing data files\n",
    "\n",
    "Preparing data files according to the [data flowchart](../../../datalake_database/#data-flowchart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onehealth_data_backend import inout\n",
    "from onehealth_data_backend import preprocess, utils\n",
    "from pathlib import Path\n",
    "import time\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to your own data folder, if needed\n",
    "data_folder = Path(\"../../../data/in/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Download ERA5-Land data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "To download ERA5-Land data using CDS's API:\n",
    "* Select the target dataset, e.g. ERA5-Land monthly averaged data from 1950 to present\n",
    "* Go to tab `Download` of the dataset and select the data variables, time range, geographical area, etc. that you want to download\n",
    "* At the end of the page, click on `Show API request code` and take notes of the following information\n",
    "    * `dataset`: name of the dataset\n",
    "    * `request`: a dictionary summarizes your download request\n",
    "* Replace the values of `dataset` and `request` in the below cell correspondingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace dataset and request with your own values\n",
    "dataset = \"reanalysis-era5-land-monthly-means\"\n",
    "request = {\n",
    "    \"product_type\": [\"monthly_averaged_reanalysis\"],\n",
    "    \"variable\": [\"2m_temperature\", \"total_precipitation\"],\n",
    "    \"year\": [\"2016\", \"2017\"],\n",
    "    \"month\": [\n",
    "        \"01\",\n",
    "        \"02\",\n",
    "        \"03\",\n",
    "        \"04\",\n",
    "        \"05\",\n",
    "        \"06\",\n",
    "        \"07\",\n",
    "        \"08\",\n",
    "        \"09\",\n",
    "        \"10\",\n",
    "        \"11\",\n",
    "        \"12\",\n",
    "    ],\n",
    "    \"time\": [\"00:00\"],\n",
    "    \"data_format\": \"netcdf\",\n",
    "    \"download_format\": \"unarchived\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format = request.get(\"data_format\")\n",
    "\n",
    "# file name of downladed data\n",
    "file_name = inout.get_filename(\n",
    "    ds_name=dataset,\n",
    "    data_format=data_format,\n",
    "    years=request[\"year\"],\n",
    "    months=request[\"month\"],\n",
    "    has_area=bool(\"area\" in request),\n",
    "    base_name=\"era5_data\",\n",
    "    variable=request[\"variable\"],\n",
    ")\n",
    "output_file = data_folder / file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "if not output_file.exists():\n",
    "    print(\"Downloading data...\")\n",
    "    inout.download_data(output_file, dataset, request)\n",
    "else:\n",
    "    print(\"Data already exists at {}\".format(output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Load settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "First we need to load the default settings which setup preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = utils.get_settings(\n",
    "    setting_path=\"default\",\n",
    "    new_settings={},\n",
    "    updated_setting_dir=None,\n",
    "    save_updated_settings=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "TBU: more details about the default settings will be provided...\n",
    "\n",
    "*Note: for future PRs, preprocessing settings may be integrated into preprocess function to make sure that these settings are saved in the same place with preprocessed files ([issue #4](https://github.com/ssciwr/onehealth-data-backend/issues/4))*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Preprocess ERA5-Land data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable truncation of dates\n",
    "settings[\"truncate_date\"] = False\n",
    "\n",
    "print(\"Preprocessing ERA5-Land data...\")\n",
    "t0 = time.time()\n",
    "preprocessed_dataset = preprocess.preprocess_data_file(\n",
    "    netcdf_file=output_file,\n",
    "    settings=settings,\n",
    ")\n",
    "t_preprocess = time.time()\n",
    "print(\"Preprocessing completed in {:.2f} seconds.\".format(t_preprocess - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The preprocessed dataset is also saved in a `.nc` file under the same folder, namely `era5_data_2016_2017_all_2t_tp_monthly_unicoords_adjlon_celsius_mm_05deg_trim`\n",
    "\n",
    "Details on regulation for the file name can be found in [Data](../../data.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Preprocess population data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Instructions for downloading population data (i.e. ISIMIP data) are presented in [Data](../../data.md) and [Data Lake](../../datalake.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "popu_file = data_folder / \"population_histsoc_30arcmin_annual_1901_2021.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings[\"truncate_date\"] = True\n",
    "# disable uncessary preprocessing steps\n",
    "settings[\"adjust_longitude\"] = False\n",
    "settings[\"convert_kelvin_to_celsius\"] = False\n",
    "settings[\"convert_m_to_mm_precipitation\"] = False\n",
    "settings[\"resample_grid\"] = False\n",
    "\n",
    "print(\"Preprocessing population data...\")\n",
    "t0 = time.time()\n",
    "preprocessed_popu = preprocess.preprocess_data_file(\n",
    "    netcdf_file=popu_file,\n",
    "    settings=settings,\n",
    ")\n",
    "t_popu = time.time()\n",
    "print(\"Preprocessing population data completed in {:.2f} seconds.\".format(t_popu - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "The preprocessed dataset is also saved in a `.nc` file under the same folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Aggregate data by NUTS regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "For analyzing data across European regions, it is more convenient to work with data aggregated by NUTS regions rather than by grid points (latitude and longitude). In this section, we demonstrate how ERA5â€‘Land and Population data can be aggregated into NUTS regions.\n",
    "\n",
    "This feature can also be applied to other datasets in NetCDF format that include the coordinates `latitude`, `longitude`, and `time` (e.g. prediction model outputs).\n",
    "\n",
    "*Note: file names of preprocessed era5 and population data should be obtained directly after the `preprocess_data_file()` function ([issue #15](https://github.com/ssciwr/onehealth-data-backend/issues/15))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUTS shapefile\n",
    "nuts_file = data_folder / \"NUTS_RG_20M_2024_4326.shp.zip\"\n",
    "\n",
    "# preprocess ERA5-Land file\n",
    "preprocessed_era5_file = (\n",
    "    data_folder\n",
    "    / \"era5_data_2016_2017_all_2t_tp_monthly_unicoords_adjlon_celsius_mm_05deg_trim.nc\"\n",
    ")\n",
    "\n",
    "# preprocess population file\n",
    "preprocessed_popu_file = (\n",
    "    data_folder / \"population_histsoc_30arcmin_annual_1901_2021_unicoords_2020_2021.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "We can aggregate singple or multiple NetCDF files with one NUTS shape file. These NetCDF files should be structured into a dictionary, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forming a dictionary for non-NUTS data\n",
    "non_nuts_data = {\n",
    "    \"era5\": (preprocessed_era5_file, None),\n",
    "    \"popu\": (preprocessed_popu_file, None),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Here, the keys represent dataset names (used to form the resulting file name), and the values are tuples containing the file path and the aggregation mapping.\n",
    "\n",
    "By default, the aggregation mapping is set to `None`, which means the `mean` function will be applied to all data variables during aggregation.\n",
    "\n",
    "An example of aggregation mapping is:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"t2m\": \"mean\", \n",
    "    \"tp\": \"sum\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "The resulting file name would be:\n",
    "\n",
    "`<NUTS_shapefile_name>_agg_<nc_dataset_names>_<min_yyyy-mm>-<max_yyy-mm>.nc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate data by NUTS regions\n",
    "t0 = time.time()\n",
    "aggregated_file = preprocess.aggregate_data_by_nuts(\n",
    "    non_nuts_data, nuts_file, normalize_time=True, output_dir=None\n",
    ")\n",
    "t1 = time.time()\n",
    "print(f\"Aggregation completed in {t1 - t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "In this example, we use the default values for `normalize_time` and `output_dir`, which are `True` and `None`, respectively.\n",
    "\n",
    "The `normalize_time` option ensures that time values in the NetCDF file are reset to the start of the day. For example, `2025-10-01T12:00:00` becomes `2025-10-01T00:00:00`. This is particularly useful for population data, where time values are recorded at midday.\n",
    "\n",
    "When `output_dir` is set to `None`, the aggregated file is saved in the same directory as the NUTS shapefile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "*Note: Since the ERA5-Land data is for 2016-2017, while the popuation data is for 2020-2021, the aggregated data would range from 2016 to 2021.*\n",
    "\n",
    "*We should truncate the population data to the same time frame for demonstration purpose. Update this after addressing [issue #6](https://github.com/ssciwr/onehealth-data-backend/issues/6)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the aggregated data\n",
    "agg_ds = xr.open_dataset(aggregated_file)\n",
    "agg_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ds[[\"t2m\", \"total-population\"]].sel(NUTS_ID=\"DE\").to_dataframe().tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onehealthdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
