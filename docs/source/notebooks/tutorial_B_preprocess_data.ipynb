{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Tutorial B: Process the downloaded data\n",
    "\n",
    "**heiplanet-data Python package - data processing and visualization of the processed data**\n",
    "\n",
    "---\n",
    "\n",
    "**Authors:** Scientific Software Center  \n",
    "**Date:** October 2025  \n",
    "**Version:** 1.0\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates how to process downloaded data files through `heiplanet-data`. You will learn how to:\n",
    "\n",
    "1. **Specify the settings for `heiplanet-data`**: Work with settings files to store data transformations\n",
    "2. **Data operations**: Carry out different data operations such as resampling of the grid\n",
    "3. **Data Visualization**: Create plots to verify the processed data\n",
    "\n",
    "## heiplanet-data\n",
    "\n",
    "The heiplanet-data package can help you transform your data in an efficient way, and stores the settings alongside your data to ensure reproducibility. The flow of operations is visualized in this flowchart:\n",
    "![data flowchart for heiplanet-data](../_static/onehealth_data_flow.jpg)\n",
    "\n",
    "For the different data sources, different operations are carried out:\n",
    "1. **Copernicus data**: Here, the columns of the data are renamed from `valid_time` to `time`, the longitude is adjusted to lie between -180 and 180 degrees, and the temperature is converted from `K` to `C`. Precipitation is converted from `m` to `mm`, and the latitude/longitude grid can be resampled to match for example the grid resolution of the ISIMIP data.\n",
    "2. **Population data**: Here, the columns of the data are renamed from `lat` to `latitude` and `long` to `longitude`, further, the range of years with data is truncated to a specified range. \n",
    "\n",
    "We will look at NUTS data and averaging in the next part of the tutorial, `tutorial C`. For now, let's start by importing the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heiplanet_data import preprocess\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to your own data folder, if needed\n",
    "data_root = Path(\"../../../data/\")\n",
    "data_folder = data_root / \"in\"\n",
    "era5_fname = \"era5_data_2016-2017_allm_2t_tp_monthly_raw.nc\"\n",
    "era5_fpath = data_folder / era5_fname\n",
    "isimip_fname = \"population_histsoc_30arcmin_annual_1901_2021.nc\"\n",
    "isimip_fpath = data_folder / isimip_fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Settings specifications\n",
    "We use `preprocess` module to perform preprocessing steps, using function named `preprocess_data_file()`:\n",
    "\n",
    "```python\n",
    "def preprocess_data_file(\n",
    "    netcdf_file: Path,\n",
    "    source: Literal[\"era5\", \"isimip\"] = \"era5\",\n",
    "    settings: Path | str = \"default\",\n",
    "    new_settings: Dict[str, Any] | None = None,\n",
    "    unique_tag: str | None = None,\n",
    ") -> Tuple[xr.Dataset, str]:\n",
    "```\n",
    "\n",
    "Here, `netcdf_file` defines the path to the input file, while `source` indicates whether the `.nc` file is downloaded from ERA5-Land or ISIMIP as these two sources have different preprocessing steps. This is relevant if you are loading default settings. If you are loading a custom settings file, as we will see later, you should specify the `source` as `era5`.\n",
    "\n",
    "The preprocessing steps are determined using a dictionary (JSON file), providied through the `settings` parameter. This parameter can either be set to a file path or to the string `\"default\"`. If a file path is given, the settings will be loaded from that file; if loading fails, the default settings for the corresponding source `era5` or `isimip` will be used instead. If `\"default\"` is specified, the default settings of the relevant source are loaded directly.\n",
    "\n",
    "If only certain fields of the default settings need to be updated, these fields and their values can be supplied as a dictionary via the `new_settings` parameter.\n",
    "\n",
    "The final settings used for preprocessing are saved to a file in the same directory as the preprocessed `.nc` file. This output directory is defined in the provided settings file. The `unique_tag` is appended to both the settings file and the resulting `.nc` file to link them together.\n",
    "\n",
    "The settings keys for the data (pre-)processing are defined as follows - you can consult this table when you adjust the settings for your specific data:\n",
    "| keyword | type and default value | description |\n",
    "|---------|----------------------|-------------|\n",
    "| `output_dir` | string, default: `\"data/processed\"` | Directory where processed data will be saved. |\n",
    "| `adjust_longitude` | boolean, default: `true` | Whether to adjust longitude values to the range [-180, 180]. |\n",
    "| `adjust_longitude_vname` | string, default: `\"longitude\"` | Variable name of the longitude values to adjust. |\n",
    "| `adjust_longitude_fname` | string, default: `\"adjlon\"` | Suffix of file names after adjusting longitude values. |\n",
    "| `convert_kelvin_to_celsius` | boolean, default: `true` | Whether to convert temperature values from Kelvin to Celsius. |\n",
    "| `convert_kelvin_to_celsius_vname` | string, default: `\"t2m\"` | Variable name of the temperature values to convert. |\n",
    "| `convert_kelvin_to_celsius_fname` | string, default: `\"celsius\"` | Suffix of file names after converting temperature values to Celsius. |\n",
    "| `convert_m_to_mm_precipitation` | boolean, default: `true` | Whether to convert precipitation values from meters to millimeters. |\n",
    "| `convert_m_to_mm_precipitation_vname` | string, default: `\"tp\"` | Variable name of the precipitation values to convert. |\n",
    "| `convert_m_to_mm_precipitation_fname` | string, default: `\"mm\"` | Suffix of file names after converting precipitation values to millimeters. |\n",
    "| `resample_grid` | boolean, default: `true` | Whether to resample the grid to a specified resolution. |\n",
    "| `resample_grid_vname` | array of strings, default: `[\"latitude\", \"longitude\"]` | Variable names of the latitude and longitude values for resampling. |\n",
    "| `resample_degree` | number, default: `0.5` | Value of the target grid resolution in degrees. |\n",
    "| `resample_grid_fname` | string, default: `\"deg_trim\"` | Suffix of file names after resampling the grid. |\n",
    "| `truncate_date` | boolean, default: `true` | Whether to truncate the time series from a specified date. |\n",
    "| `truncate_date_from` | string, default: `\"2016-01-01\"` | Date in YYYY-MM-DD to truncate the time series from. |\n",
    "| `truncate_date_to` | string, default: `\"2017-12-31\"` | Date in YYYY-MM-DD to truncate the time series to. |\n",
    "| `truncate_date_vname` | string, default: `\"time\"` | Variable name of the time values to truncate. |\n",
    "| `unify_coords` | boolean, default: `true` | Whether to unify coordinate names in the data file. |\n",
    "| `unify_coords_fname` | string, default: `\"unicoords\"` | Suffix of file names after unifying coordinate names. |\n",
    "| `uni_coords` | object, default: `{\"lat\": \"latitude\", \"lon\": \"longitude\", \"valid_time\": \"time\"}` | Mapping of variable names to their new names. |\n",
    "\n",
    "The following subsections illustrate how the settings in the preprocessing are applied to ERA5-Land data and ISIMIP data.\n",
    "\n",
    "## 2. Data operations\n",
    "\n",
    "### Preprocess ERA5-Land data\n",
    "\n",
    "Default settings for `.nc` files from ERA5-Land are:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"output_dir\": \"../../../data/processed\",          # Directory for saved processed files\n",
    "    \"adjust_longitude\": true,                         # Enable longitude adjustment to [-180, 180] range\n",
    "    \"adjust_longitude_vname\": \"longitude\",            # Variable name for longitude values\n",
    "    \"adjust_longitude_fname\": \"adjlon\",               # File suffix after longitude adjustment\n",
    "    \"convert_kelvin_to_celsius\": true,                # Enable temperature conversion from K to °C\n",
    "    \"convert_kelvin_to_celsius_vname\": \"t2m\",         # Variable name for temperature data\n",
    "    \"convert_kelvin_to_celsius_fname\": \"celsius\",     # File suffix after temperature conversion\n",
    "    \"convert_m_to_mm_precipitation\": true,            # Enable precipitation conversion from m to mm\n",
    "    \"convert_m_to_mm_precipitation_vname\": \"tp\",      # Variable name for precipitation data\n",
    "    \"convert_m_to_mm_precipitation_fname\": \"mm\",      # File suffix after precipitation conversion\n",
    "    \"resample_grid\": true,                            # Enable grid resampling to specified resolution\n",
    "    \"resample_grid_vname\": [\"latitude\", \"longitude\"], # Variable names for lat/lon coordinates\n",
    "    \"resample_degree\": 0.5,                           # Target grid resolution in degrees\n",
    "    \"resample_grid_fname\": \"deg_trim\",                # File suffix after grid resampling\n",
    "    \"unify_coords\": true,                             # Enable coordinate name standardization\n",
    "    \"unify_coords_fname\": \"unicoords\",                # File suffix after coordinate unification\n",
    "    \"uni_coords\": {                                   # Mapping of old to new coordinate names\n",
    "        \"valid_time\": \"time\"                          # Rename 'valid_time' to 'time'\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "The output directory for all preprocessed files and utilized settings files is set to path `\"data/processed\"`. This path is ***relative*** to the current file. For `.nc` files downloaded from ERA5-Land, we need to perform the following preprocessing steps:\n",
    "\n",
    "* adjust longitude from range $[0..360]$ to $[-180..180]$\n",
    "* convert temperature values from Kelvin to Celsius\n",
    "* convert precipitation values from meter to millimeter\n",
    "* resample the grid from $0.1°$ to $0.5°$\n",
    "* rename coordinates to a unified name set, i.e. `latitude`, `longitude`, and `time`\n",
    "\n",
    "We toggle these steps by setting the corresponding field to `true` or `false`, e.g. `\"unify_coords\": false` disables coordinate renaming.\n",
    "\n",
    "Fields end with `_vname` specify which data variables in a `.nc` file will be used for the corresponding preprocessing step. While fields with `_fname` define the suffix to add into the file name after the preprocessing step run successfully. For an overview of file name transformation, see [tutorial A](./tutorial_A_download_data.ipynb).\n",
    "\n",
    "Ultimately, the `uni_coords` dictionary defines the mapping between old and new coordinate names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Preprocessing ERA5-Land data: {era5_fpath}\")\n",
    "t0 = time.time()\n",
    "preprocessed_dataset, era5_pfname = preprocess.preprocess_data_file(\n",
    "    netcdf_file=era5_fpath,\n",
    "    source=\"era5\",\n",
    "    settings=\"default\",\n",
    "    new_settings=None,\n",
    "    unique_tag=None,\n",
    ")\n",
    "t_preprocess = time.time()\n",
    "print(f\"Preprocessing completed in {t_preprocess - t0:.2f} seconds.\")\n",
    "print(f\"Name of preprocessed file: {era5_pfname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Preprocess population data\n",
    "Default settings for `.nc` files from ISIMIP are:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"output_dir\": \"../../../data/processed\",    # Directory for saved processed files\n",
    "    \"truncate_date\": true,                      # Enable time series truncation to specific date range\n",
    "    \"truncate_date_from\": \"2016-01-01\",         # Start date for data truncation (YYYY-MM-DD format)\n",
    "    \"truncate_date_to\": \"2017-12-31\",           # End date for data truncation (YYYY-MM-DD format)\n",
    "    \"truncate_date_vname\": \"time\",              # Variable name for time dimension\n",
    "    \"unify_coords\": true,                       # Enable coordinate name standardization\n",
    "    \"unify_coords_fname\": \"unicoords\",          # File suffix after coordinate unification\n",
    "    \"uni_coords\": {                             # Mapping of old to new coordinate names\n",
    "        \"lat\": \"latitude\",                      # Rename 'lat' to 'latitude'\n",
    "        \"lon\": \"longitude\"                      # Rename 'lon' to 'longitude'\n",
    "    }\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "The resulting files (data and settings) will be saved into `output_dir` (***relative*** path to the current file). To preprocess `.nc` files from ISIMIP, we consider these steps:\n",
    "\n",
    "* truncate data in a specific range, with start and end timepoints included\n",
    "* unify coordinate names\n",
    "\n",
    "The naming convention for fields in these settings follows the same pattern described above for ERA5-Land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Preprocessing ISIMIP data: {isimip_fpath}\")\n",
    "t0 = time.time()\n",
    "preprocessed_popu, isimip_pfname = preprocess.preprocess_data_file(\n",
    "    netcdf_file=isimip_fpath,\n",
    "    source=\"isimip\",\n",
    "    settings=\"default\",\n",
    "    new_settings=None,\n",
    "    unique_tag=None,\n",
    ")\n",
    "t_popu = time.time()\n",
    "print(f\"Preprocessing ISIMIP data completed in {t_popu - t0:.2f} seconds.\")\n",
    "print(f\"Name of preprocessed file: {isimip_pfname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Process custom data\n",
    "For custom data, there are no default settings. You should specify the source type as `era5` when you call the preprocess function, and provide your own custom dictionary with the desired settings. An example is shown here for model predictions, resampling the prediction to a grid of 0.25 degrees resolution from an initial 0.5 degrees resolution.\n",
    "\n",
    "First we need to download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jmodel_fpath = data_folder / \"output_JModel_global.nc\"\n",
    "settings_file_path = data_folder / \"settings_JModel_global.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We are providing a `settings_file_path`, where we can either deposit a settings file that contains the settings to be used (for example, if you rerun the same processes multiple times), or we can also save the current settings as input to that file. Note that the settings are always also stored with your processed data, so that you can reproduce any processing steps.\n",
    "\n",
    "For now, we will define the settings in this notebook and store them in `settings_file_path`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"output_dir\": \"../../../data/processed\",\n",
    "    \"resample_grid\": True,  # Enable grid resampling to specified resolution\n",
    "    \"resample_grid_vname\": [\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "    ],  # Variable names for lat/lon coordinates\n",
    "    \"resample_degree\": 0.25,  # Target grid resolution in degrees\n",
    "    \"resample_grid_fname\": \"deg_trim\",  # File suffix after grid resampling\n",
    "}\n",
    "# write the settings to a json file\n",
    "json.dump(settings, open(settings_file_path, \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Now we can preprocess the custom data file, using the settings defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Preprocessing JModel output data: {jmodel_fpath}\")\n",
    "t0 = time.time()\n",
    "preprocessed_jmodel, jmodel_pfname = preprocess.preprocess_data_file(\n",
    "    netcdf_file=jmodel_fpath,\n",
    "    source=\"era5\",\n",
    "    settings=settings_file_path,\n",
    "    new_settings=None,\n",
    "    unique_tag=None,\n",
    ")\n",
    "t_jmodel = time.time()\n",
    "print(f\"Preprocessing JModel data completed in {t_jmodel - t0:.2f} seconds.\")\n",
    "print(f\"Name of preprocessed file: {jmodel_pfname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Alternatively, you can provide the settings as a dictionary to `new_settings`, overwriting the `era5` default settings on the go.\n",
    "\n",
    "## 3. Creating plots of the (pre-)processed data\n",
    "\n",
    "For this, we again use `xarray` and read the data into `xarray` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_ds_processed = xr.open_dataset(data_root / \"processed\" / era5_pfname)\n",
    "isimip_ds_processed = xr.open_dataset(data_root / \"processed\" / isimip_pfname)\n",
    "jmodel_ds_processed = xr.open_dataset(data_root / \"processed\" / jmodel_pfname)\n",
    "\n",
    "# for a comparison, also open the raw ERA5 data\n",
    "era5_ds_raw = xr.open_dataset(era5_fpath)\n",
    "isimip_ds_raw = xr.open_dataset(isimip_fpath)\n",
    "jmodel_ds_raw = xr.open_dataset(jmodel_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Now we can plot the era5 processed and raw data for selected months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot for raw and processed data next to each other\n",
    "# plot the cartesian grid data of t2m for 2016-2 and 2016-8\n",
    "\n",
    "selected_times = [\n",
    "    \"2016-02-01\",\n",
    "    \"2016-08-01\",\n",
    "]\n",
    "\n",
    "# Create figure with subplots for temperature comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle(\"ERA5 Temperature Data Comparison: Raw vs Processed\", fontsize=16, y=0.94)\n",
    "\n",
    "# Plot raw data\n",
    "for i, time_val in enumerate(selected_times):\n",
    "    raw_data = era5_ds_raw.sel(valid_time=time_val, method=\"nearest\")\n",
    "    im1 = raw_data.t2m.plot.pcolormesh(\n",
    "        ax=axes[0, i], cmap=\"coolwarm\", robust=True, add_colorbar=False\n",
    "    )\n",
    "    axes[0, i].set_title(f\"Raw - {time_val[:7]}\", pad=15)\n",
    "\n",
    "    processed_data = era5_ds_processed.sel(time=time_val, method=\"nearest\")\n",
    "    im2 = processed_data.t2m.plot.pcolormesh(\n",
    "        ax=axes[1, i], cmap=\"coolwarm\", robust=True, add_colorbar=False\n",
    "    )\n",
    "    axes[1, i].set_title(f\"Processed - {time_val[:7]}\", pad=15)\n",
    "\n",
    "# Adjust layout with more spacing\n",
    "plt.tight_layout(rect=[0, 0.05, 0.98, 0.94])  # Leave space for colorbars on the right\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.3)  # Add space between subplots\n",
    "\n",
    "# Add separate colorbars for each row\n",
    "cbar1 = fig.colorbar(im1, ax=axes[0, :], orientation=\"vertical\", pad=0.02, shrink=0.8)\n",
    "cbar1.set_label(\"Raw Temperature (K)\", fontsize=10)\n",
    "\n",
    "cbar2 = fig.colorbar(im2, ax=axes[1, :], orientation=\"vertical\", pad=0.02, shrink=0.8)\n",
    "cbar2.set_label(\"Processed Temperature (°C)\", fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Note that due to the different scale between K and C, the shading of the plots is slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same for the precipitation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle(\n",
    "    \"ERA5 Precipitation Data Comparison: Raw vs Processed\", fontsize=16, y=0.94\n",
    ")\n",
    "\n",
    "# Plot raw data\n",
    "for i, time_val in enumerate(selected_times):\n",
    "    raw_data = era5_ds_raw.sel(valid_time=time_val, method=\"nearest\")\n",
    "    im1 = raw_data.tp.plot.pcolormesh(\n",
    "        ax=axes[0, i], cmap=\"coolwarm\", robust=True, add_colorbar=False\n",
    "    )\n",
    "    axes[0, i].set_title(f\"Raw - {time_val[:7]}\", pad=15)\n",
    "\n",
    "    processed_data = era5_ds_processed.sel(time=time_val, method=\"nearest\")\n",
    "    im2 = processed_data.tp.plot.pcolormesh(\n",
    "        ax=axes[1, i], cmap=\"coolwarm\", robust=True, add_colorbar=False\n",
    "    )\n",
    "    axes[1, i].set_title(f\"Processed - {time_val[:7]}\", pad=15)\n",
    "\n",
    "# Adjust layout with more spacing\n",
    "plt.tight_layout(rect=[0, 0.05, 0.98, 0.94])  # Leave space for colorbars on the right\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.3)  # Add space between subplots\n",
    "\n",
    "# Add separate colorbars for each row\n",
    "cbar1 = fig.colorbar(im1, ax=axes[0, :], orientation=\"vertical\", pad=0.02, shrink=0.8)\n",
    "cbar1.set_label(\"Raw precipitation (m)\", fontsize=10)\n",
    "\n",
    "cbar2 = fig.colorbar(im2, ax=axes[1, :], orientation=\"vertical\", pad=0.02, shrink=0.8)\n",
    "cbar2.set_label(\"Processed precipitation (mm)\", fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same for the population\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle(\"Population Data Comparison: Raw vs Processed\", fontsize=16, y=0.94)\n",
    "\n",
    "# Plot raw data\n",
    "for i, time_val in enumerate(selected_times):\n",
    "    raw_data = isimip_ds_raw.sel(time=time_val, method=\"nearest\")\n",
    "    im1 = raw_data[\"total-population\"].plot.pcolormesh(\n",
    "        ax=axes[0, i], cmap=\"coolwarm\", robust=True, add_colorbar=False\n",
    "    )\n",
    "    axes[0, i].set_title(f\"Raw - {time_val[:7]}\", pad=15)\n",
    "\n",
    "    processed_data = isimip_ds_processed.sel(time=time_val, method=\"nearest\")\n",
    "    im2 = processed_data[\"total-population\"].plot.pcolormesh(\n",
    "        ax=axes[1, i], cmap=\"coolwarm\", robust=True, add_colorbar=False\n",
    "    )\n",
    "    axes[1, i].set_title(f\"Processed - {time_val[:7]}\", pad=15)\n",
    "\n",
    "# Adjust layout with more spacing\n",
    "plt.tight_layout(rect=[0, 0.05, 0.98, 0.94])  # Leave space for colorbars on the right\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.3)  # Add space between subplots\n",
    "\n",
    "# Add separate colorbars for each row\n",
    "cbar1 = fig.colorbar(im1, ax=axes[0, :], orientation=\"vertical\", pad=0.02, shrink=0.8)\n",
    "cbar1.set_label(\"Total population\", fontsize=10)\n",
    "\n",
    "cbar2 = fig.colorbar(im2, ax=axes[1, :], orientation=\"vertical\", pad=0.02, shrink=0.8)\n",
    "cbar2.set_label(\"Total population\", fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "And as well for the data from the model output. Here, we have changed the grid resolution (in this case, upsampled), but in a more general case this would be downsampled from a higher to a lower resolution, to preserve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with subplots for model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle(\"Jmodel Data Comparison: Raw vs Processed\", fontsize=16, y=0.94)\n",
    "\n",
    "# Plot raw data\n",
    "for i, time_val in enumerate(selected_times):\n",
    "    raw_data = jmodel_ds_raw.sel(time=time_val, method=\"nearest\")\n",
    "    im1 = raw_data.R0.plot.pcolormesh(\n",
    "        ax=axes[0, i], cmap=\"coolwarm\", robust=True, add_colorbar=False\n",
    "    )\n",
    "    axes[0, i].set_title(f\"Raw - {time_val[:7]}\", pad=15)\n",
    "\n",
    "    processed_data = jmodel_ds_processed.sel(time=time_val, method=\"nearest\")\n",
    "    im2 = processed_data.R0.plot.pcolormesh(\n",
    "        ax=axes[1, i], cmap=\"coolwarm\", robust=True, add_colorbar=False\n",
    "    )\n",
    "    axes[1, i].set_title(f\"Processed - {time_val[:7]}\", pad=15)\n",
    "\n",
    "# Adjust layout with more spacing\n",
    "plt.tight_layout(rect=[0, 0.05, 0.98, 0.94])  # Leave space for colorbars on the right\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.3)  # Add space between subplots\n",
    "\n",
    "# Add separate colorbars for each row\n",
    "cbar1 = fig.colorbar(im1, ax=axes[0, :], orientation=\"vertical\", pad=0.02, shrink=0.8)\n",
    "cbar1.set_label(\"Raw Temperature (K)\", fontsize=10)\n",
    "\n",
    "cbar2 = fig.colorbar(im2, ax=axes[1, :], orientation=\"vertical\", pad=0.02, shrink=0.8)\n",
    "cbar2.set_label(\"Processed Temperature (°C)\", fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to zoom in to a region to inspect the different gridding\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle(\"Jmodel Data Comparison: Raw vs Processed\", fontsize=16, y=0.94)\n",
    "\n",
    "# Plot raw data\n",
    "for i, time_val in enumerate(selected_times):\n",
    "    raw_data = jmodel_ds_raw.sel(time=time_val, method=\"nearest\")\n",
    "    im1 = raw_data.R0.plot.pcolormesh(\n",
    "        ax=axes[0, i], cmap=\"coolwarm\", robust=True, add_colorbar=False\n",
    "    )\n",
    "    axes[0, i].set_title(f\"Raw - {time_val[:7]}\", pad=15)\n",
    "    axes[0, i].set_xlim(-11, 35)  # Set axis limits\n",
    "    axes[0, i].set_ylim(35, 60)\n",
    "\n",
    "    processed_data = jmodel_ds_processed.sel(time=time_val, method=\"nearest\")\n",
    "    im2 = processed_data.R0.plot.pcolormesh(\n",
    "        ax=axes[1, i], cmap=\"coolwarm\", robust=True, add_colorbar=False\n",
    "    )\n",
    "    axes[1, i].set_title(f\"Processed - {time_val[:7]}\", pad=15)\n",
    "    axes[1, i].set_xlim(-11, 35)  # Set axis limits\n",
    "    axes[1, i].set_ylim(35, 60)\n",
    "\n",
    "# Adjust layout with more spacing\n",
    "plt.tight_layout(rect=[0, 0.05, 0.98, 0.94])  # Leave space for colorbars on the right\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.3)  # Add space between subplots\n",
    "\n",
    "# Add separate colorbars for each row\n",
    "cbar1 = fig.colorbar(im1, ax=axes[0, :], orientation=\"vertical\", pad=0.02, shrink=0.8)\n",
    "cbar1.set_label(\"Raw Temperature (K)\", fontsize=10)\n",
    "\n",
    "cbar2 = fig.colorbar(im2, ax=axes[1, :], orientation=\"vertical\", pad=0.02, shrink=0.8)\n",
    "cbar2.set_label(\"Processed Temperature (°C)\", fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heiplanet-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
