{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Tutorial A: Download Data from Copernicus and ISIMIP\n",
    "\n",
    "**onehealth-data Python package - data download and visualization of the raw data**\n",
    "\n",
    "---\n",
    "\n",
    "**Authors:** Scientific Software Center  \n",
    "**Date:** October 2025  \n",
    "**Version:** 1.0\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates how to download data files through the Copernicus and ISMIP API. You will learn how to:\n",
    "\n",
    "- Download ERA5 climate data\n",
    "- Download population data from ISIMIP\n",
    "- Visualize the data to verify its integrity and correctness\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Preparing data files\n",
    "\n",
    "Preparing data files according to the [data flowchart](../../datalake.md#data-flowchart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onehealth_data_backend import inout\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr\n",
    "from isimip_client.client import ISIMIPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to your own data folder, if needed\n",
    "data_root = Path(\"../../../data/\")\n",
    "data_folder = data_root / \"in\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Download ERA5-Land data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "To download ERA5-Land data using CDS's API:\n",
    "* Select the target dataset, e.g. ERA5-Land monthly averaged data from 1950 to present\n",
    "* Go to tab `Download` of the dataset and select the data variables, time range, geographical area, etc. that you want to download\n",
    "* At the end of the page, click on `Show API request code` and take notes of the following information\n",
    "    * `dataset`: name of the dataset\n",
    "    * `request`: a dictionary summarizes your download request\n",
    "* Replace the values of `dataset` and `request` in the below cell correspondingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace dataset and request with your own values\n",
    "dataset = \"reanalysis-era5-land-monthly-means\"\n",
    "request = {\n",
    "    \"product_type\": [\"monthly_averaged_reanalysis\"],\n",
    "    \"variable\": [\"2m_temperature\", \"total_precipitation\"],\n",
    "    \"year\": [\"2016\", \"2017\"],\n",
    "    \"month\": [\n",
    "        \"01\",\n",
    "        \"02\",\n",
    "        \"03\",\n",
    "        \"04\",\n",
    "        \"05\",\n",
    "        \"06\",\n",
    "        \"07\",\n",
    "        \"08\",\n",
    "        \"09\",\n",
    "        \"10\",\n",
    "        \"11\",\n",
    "        \"12\",\n",
    "    ],\n",
    "    \"time\": [\"00:00\"],\n",
    "    \"data_format\": \"netcdf\",\n",
    "    \"download_format\": \"unarchived\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format = request.get(\"data_format\")\n",
    "\n",
    "# file name of downladed data\n",
    "era5_fname = inout.get_filename(\n",
    "    ds_name=dataset,\n",
    "    data_format=data_format,\n",
    "    years=request[\"year\"],\n",
    "    months=request[\"month\"],\n",
    "    has_area=bool(\"area\" in request),\n",
    "    base_name=\"era5_data\",\n",
    "    variables=request[\"variable\"],\n",
    ")\n",
    "era5_fpath = data_folder / era5_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "if not era5_fpath.exists():\n",
    "    print(\"Downloading data...\")\n",
    "    inout.download_data(era5_fpath, dataset, request)\n",
    "else:\n",
    "    print(\"Data already exists at {}\".format(era5_fpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Special download for total precipitation data from ERA5-Land Hourly dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "`P-model` requires total precipitation data downloaded from dataset `ERA5-Land hourly data from 1950 to present`.\n",
    "\n",
    "Due to the nature of this dataset, value at `00:00` is total precipitation of the previous day (see [here](https://confluence.ecmwf.int/pages/viewpage.action?pageId=197702790))\n",
    "\n",
    "To get correct precipitation values from `01.01.2016` to `31.12.2017`, we need to download data from `02.01.2016` to `01.01.2018`. The current CDS request API does not allow downloading data in a single request for ranges that are not full calendar years.\n",
    "\n",
    "We implemented a special function for this case.\n",
    "\n",
    "```python\n",
    "def download_total_precipitation_from_hourly_era5_land(\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    area: List[float] | None = None,\n",
    "    out_dir: Path = Path(\".\"),\n",
    "    base_name: str = \"era5_data\",\n",
    "    data_format: str = \"netcdf\",\n",
    "    ds_name: str = \"reanalysis-era5-land\",\n",
    "    coord_name: str = \"valid_time\",\n",
    "    var_name: str = \"total_precipitation\",\n",
    "    clean_tmp_files: bool = False,\n",
    ") -> str:\n",
    "```\n",
    "\n",
    "Input for this function includes:\n",
    "\n",
    "* `start_date` and `end_date` in the format of \"YYYY-MM-DD\"\n",
    "* `area` indicates the area to download; `None` means the entire globe.\n",
    "* `out_dir`: output directory to store the downloaded file\n",
    "* `base_name`: base string used to name the output file. File name is described in [Naming convention - Special case](../../data.md#special-case)\n",
    "* `data_format`: can be `netcdf` or `grib`\n",
    "* `ds_name`, `coord_name`, and `var_name` represent the dataset name, coordinate name, and data variable name in the dataset. Please only change these values when CDS changes the corresponding names.\n",
    "* `clean_tmp_files` parameter can be set to `False` to retain the downloaded temporary files, which store data for smaller sub-ranges derived from the overall date range. For example, the range `2016-01-01` to `2017-12-31` would be split into sub-ranges `2016-01-02` to `2016-12-31`, `2017-01-01` to `2017-12-31`, and `2018-01-01` to `2018-01-01`, because the timestamps are shifted one day forward.\n",
    "\n",
    "The function handles time shifting, downloads the data, adjusts the time coordinate back to the target range, and returns the output file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download total precipitation data from ERA5-Land Hourly dataset\n",
    "# from 2016-01-01 to 2017-12-31\n",
    "start_time = \"2016-01-01\"\n",
    "end_time = \"2017-12-31\"\n",
    "tp_era5_hourly_file = inout.download_total_precipitation_from_hourly_era5_land(\n",
    "    start_date=start_time,\n",
    "    end_date=end_time,\n",
    "    area=None,\n",
    "    out_dir=data_folder,\n",
    "    base_name=\"era5_data\",\n",
    "    data_format=\"netcdf\",\n",
    "    ds_name=\"reanalysis-era5-land\",\n",
    "    coord_name=\"valid_time\",\n",
    "    var_name=\"total_precipitation\",\n",
    "    clean_tmp_files=False,  # keep temporary files for checking\n",
    ")\n",
    "tp_era5_hourly_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_era5_hourly_ds = xr.open_dataset(tp_era5_hourly_file)\n",
    "tp_era5_hourly_ds[\"valid_time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Download ISIMIP data (population data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "To download ISIMIP data manually, please follow the instruction in [Data](../../data.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "To download the data using ISIMIP's APIs, please perform these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize ISIMIP client\n",
    "client = ISIMIPClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for population data\n",
    "response = client.datasets(\n",
    "    path=\"ISIMIP3a/InputData/socioeconomic/pop/histsoc/population\"\n",
    ")  # this path is similar to the one in ISIMIP's website\n",
    "\n",
    "for dataset in response[\"results\"]:\n",
    "    print(\"Dataset found: {}\".format(dataset[\"path\"]))\n",
    "\n",
    "# download population data file, 1901_2021\n",
    "for dataset in response[\"results\"]:\n",
    "    for file in dataset[\"files\"]:\n",
    "        if \"1901_2021\" in file[\"name\"]:\n",
    "            isimip_fpath = data_folder / file[\"name\"]\n",
    "            if isimip_fpath.exists():\n",
    "                print(f\"Population data file already exists: {file['name']}\")\n",
    "            else:\n",
    "                print(f\"Downloading population data file: {file['name']}\")\n",
    "                client.download(file[\"file_url\"], path=data_folder)\n",
    "            break  # exit after first match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Open the files and read contents into xarray datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load netCDF files\n",
    "ds_era5 = xr.open_dataset(era5_fpath)\n",
    "ds_isimip = xr.open_dataset(isimip_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Plot the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cartesian grid data of t2m and tp for 2016-2017, all months\n",
    "ds_era5.t2m.plot.pcolormesh(\n",
    "    col=\"valid_time\", col_wrap=4, cmap=\"coolwarm\", robust=True, figsize=(15, 10)\n",
    ")\n",
    "plt.savefig(\"era5_2016_2017_plots.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-be",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
